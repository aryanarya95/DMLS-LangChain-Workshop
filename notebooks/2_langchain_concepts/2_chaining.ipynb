{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain Chaining: Concepts and Examples**\n",
    "\n",
    "## **ðŸ“Œ Overview**\n",
    "Chaining in LangChain allows for the **sequencing of multiple operations**, enabling more complex and structured \\\n",
    "interactions with language models. By combining different processing steps, you can build advanced workflows \\\n",
    "that enhance prompt flexibility and efficiency.\n",
    "\n",
    "In this section, we will cover key **chaining concepts**, including:\n",
    "\n",
    "- **Basic Chaining** â€“ Linking multiple calls together in sequence using LangChain Expression Language (LCEL).\n",
    "- **Understanding Runnables** â€“ The core building blocks for executing chains.  \n",
    "- **Extended Processing** â€“ Transforming and structuring responses dynamically.  \n",
    "- **Parallel Processing** â€“ Running multiple operations simultaneously for efficiency.  \n",
    "- **Branching Processing** â€“ Handling multiple decision paths based on input conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: google-generativeai 0.8.4\n",
      "Uninstalling google-generativeai-0.8.4:\n",
      "  Successfully uninstalled google-generativeai-0.8.4\n",
      "Found existing installation: google-ai-generativelanguage 0.6.17\n",
      "Uninstalling google-ai-generativelanguage-0.6.17:\n",
      "  Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.1 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies \n",
    "%pip install -q python-dotenv langchain-core langchain-google-genai langchain\n",
    "%pip uninstall -y google-generativeai google-ai-generativelanguage\n",
    "%pip install -q google-generativeai==0.8.4 google-ai-generativelanguage==0.6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence, RunnableParallel, RunnableBranch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obtain a Google Gemini API Key (GOOGLE COLLAB SETUP):**\n",
    "\n",
    "If you have a Google Gemini API Key: \n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below\n",
    "\n",
    "Otherwise:  \n",
    "- Go to the Google AI Studio API Console: [Google AI Studio](https://aistudio.google.com/prompts/new_chat)\n",
    "- Sign in with your Google account and create a new API key.\n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API key manually\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your_google_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Environment Variables (LOCAL SETUP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Basic Chaining**  \n",
    "\n",
    "Sequentially links components using LCEL for structured and reusable workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with the essay topic.  I need to know what you want me to write about before I can write a 200-word essay.\n",
      "Please provide me with the essay topic.  I need to know what you want me to write about before I can write a 200-word essay.\n"
     ]
    }
   ],
   "source": [
    "# 1) Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# 2) Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a convincing essay writer.\"), \n",
    "    (\"human\", \"Write a {essay_length} word essay on {essay_position}.\"),\n",
    "])\n",
    "\n",
    "# 3) Create chain using LangChain Expression Langauge (LCEL)\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# 4) Get LLM response (after retrieving user input)\n",
    "position = input(\"What is your essay position?: \").strip()\n",
    "response = chain.invoke({\n",
    "    \"essay_length\": 200, \n",
    "    \"essay_position\": position})\n",
    "print(response)\n",
    "\n",
    "# ------------COMPARISON WITH MANUAL PROMPT FORMATTING------------\n",
    "\n",
    "# Get user input and format prompt\n",
    "position = input(\"What is your essay position?: \").strip()\n",
    "prompt = prompt_template.invoke({\n",
    "    \"essay_length\": 200, \n",
    "    \"essay_position\": position})\n",
    "\n",
    "# Get LLM response \n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understanding Runnables**  \n",
    "Defines execution logic within chains, enabling modular and reusable workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 4) Run chain (both 4a and 4b are the same!)\u001b[39;00m\n\u001b[32m     26\u001b[39m params = {\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdays\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m30\u001b[39m,\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minterest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhiking\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdestination\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSouth America\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m manual_chain_response = \u001b[43mmanual_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m piped_chain_response = piped_chain.invoke(params)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-----Manual chain response-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanual_chain_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4719\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4705\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4706\u001b[39m \n\u001b[32m   4707\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4716\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4726\u001b[39m     msg = (\n\u001b[32m   4727\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4728\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4729\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4573\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4571\u001b[39m                 output = chunk\n\u001b[32m   4572\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4573\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4574\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(prompt_val)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2) Wrap each processing step in RunnableLambda \u001b[39;00m\n\u001b[32m     11\u001b[39m format_prompt = RunnableLambda(\u001b[38;5;28;01mlambda\u001b[39;00m inputs: prompt_template.format_prompt(**inputs))\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m invoke_model = RunnableLambda(\u001b[38;5;28;01mlambda\u001b[39;00m prompt_val: \u001b[43mllm\u001b[49m.invoke(prompt_val.to_messages()))\n\u001b[32m     13\u001b[39m parse_output = RunnableLambda(\u001b[38;5;28;01mlambda\u001b[39;00m llm_response: llm_response.content)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 3a) Manually assemble chain\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# 2) Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert travel guide. You create detailed, day-by-day itineraries \" \\\n",
    "        \"tailored to a traveler's interests.\"),\n",
    "        (\"human\", \"Create a {days}-day itinerary for a {interest} trip in {destination}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3) Wrap each processing step in RunnableLambda \n",
    "format_prompt = RunnableLambda(lambda inputs: prompt_template.format_prompt(**inputs))\n",
    "invoke_model = RunnableLambda(lambda prompt_val: llm.invoke(prompt_val.to_messages()))\n",
    "parse_output = RunnableLambda(lambda llm_response: llm_response.content)\n",
    "\n",
    "# 4a) Manually assemble chain\n",
    "manual_chain = RunnableSequence(\n",
    "    first=format_prompt, \n",
    "    middle=[invoke_model], \n",
    "    last=parse_output\n",
    ")\n",
    "\n",
    "# 4b) Or contruct using LCEL pipes\n",
    "piped_chain = format_prompt | invoke_model | parse_output\n",
    "\n",
    "# 5) Run chain (both 4a and 4b are the same!)\n",
    "params = {\n",
    "    \"days\": 30,\n",
    "    \"interest\": \"hiking\",\n",
    "    \"destination\": \"South America\"\n",
    "}\n",
    "manual_chain_response = manual_chain.invoke(params)\n",
    "piped_chain_response = piped_chain.invoke(params)\n",
    "\n",
    "print(f\"-----Manual chain response-----\\n: {manual_chain_response}\\n\\n\")\n",
    "print(f\"-----Piped chain response-----\\n: {piped_chain_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run chain\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m output = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdays\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m        \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minterest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhiking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdestination\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVietnam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#----------Either way, when we run chain....\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 1st runnable\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4719\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4705\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4706\u001b[39m \n\u001b[32m   4707\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4716\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4726\u001b[39m     msg = (\n\u001b[32m   4727\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4728\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4729\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4573\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4571\u001b[39m                 output = chunk\n\u001b[32m   4572\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4573\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4574\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(inputs)\u001b[39m\n\u001b[32m      9\u001b[39m action_prompt_template = ChatPromptTemplate.from_messages([\n\u001b[32m     10\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mYou extract action items from a meeting summary.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[33m\"\u001b[39m\u001b[33mFrom the meeting \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{title}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, list the action items \u001b[39m\u001b[33m\"\u001b[39m \\\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mas bullet points, each starting with \u001b[39m\u001b[33m'\u001b[39m\u001b[33m- \u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{summary}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m ])\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 3) Wrap each processing step in runnable \u001b[39;00m\n\u001b[32m     16\u001b[39m summarize_transcript = RunnableLambda(\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m inputs: {\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m:   \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m: llm.invoke(\n\u001b[32m     20\u001b[39m             summarize_prompt_template.format_prompt(text=inputs[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]).to_messages()\n\u001b[32m     21\u001b[39m         ).content.strip()\n\u001b[32m     22\u001b[39m     }\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m extract_actions = RunnableLambda(\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m summary_data: {\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: summary_data[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     }\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m parse_actions = RunnableLambda(\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m actions_data: [\n\u001b[32m     39\u001b[39m         line.strip(\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     ]\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'title'"
     ]
    }
   ],
   "source": [
    "# Run chain\n",
    "output = chain.invoke({\n",
    "    \"days\": 30,\n",
    "    \"interest\": \"hiking\",\n",
    "    \"destination\": \"South America\"\n",
    "})\n",
    "print(output)\n",
    "\n",
    "#----------Either way, when we run chain....\n",
    "\n",
    "# 1st runnable\n",
    "prompt_val = prompt_template.format_prompt({\n",
    "    \"days\": 30,\n",
    "    \"interest\": \"hiking\",\n",
    "    \"destination\": \"South America\"\n",
    "})\n",
    "# prompt_val is holds structured SYSTEM + HUMAN messages\n",
    "\n",
    "# 2nd runnable\n",
    "messages = prompt_val.to_messages()\n",
    "# messages transforms prompt_val into list of chat messages\n",
    "\n",
    "llm_response = llm.invoke(messages)\n",
    "# llm_response returns LLM response containing content and metadata \n",
    "\n",
    "# 3rd runnable\n",
    "parse_output = llm_response.content\n",
    "# parse_output extracts the content from the llm_response\n",
    "\n",
    "print(parse_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extended Processing**\n",
    "Transforms and structures responses for enhanced output customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions items for Business Meeting 2025-05-01\n",
      "\n",
      "Bob: Post budget scenarios spreadsheet to #marketing Slack by 5 PM today.\n",
      "Dana: Deliver influencer-network recommendation deck by Wednesday.\n",
      "Emily: Share outreach email template by Thursday.\n",
      "Frank: Draft landing-page copy by Monday morning.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ----Define prompt templates------------------------\n",
    "action_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You extract action items from a meeting transcript.\"),\n",
    "    (\"human\", \"List the action items for this meeting transcript,\" \\\n",
    "        \"as bullet points, each starting with '- ':\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "# ----Create runnables------------------------\n",
    "extract_actions = RunnableLambda(\n",
    "    lambda summary_data: {\n",
    "        \"title\": summary_data[\"title\"],\n",
    "        \"actions\": llm.invoke(\n",
    "            action_template.format_prompt(\n",
    "                text=summary_data[\"text\"]\n",
    "            ).to_messages()\n",
    "        ).content.strip()\n",
    "    }\n",
    ")\n",
    "\n",
    "parse_actions = RunnableLambda(\n",
    "    lambda actions_data: {\n",
    "        \"title\": actions_data[\"title\"], \n",
    "        \"actions\": [line.strip(\"- \").strip()\n",
    "            for line in actions_data[\"actions\"].splitlines()\n",
    "            if line.strip().startswith(\"-\")]\n",
    "    }\n",
    ")\n",
    "\n",
    "# ----Assemble chain------------------------\n",
    "chain = extract_actions | parse_actions\n",
    "\n",
    "meeting_title = \"Business Meeting 2025-05-01\"\n",
    "meeting_text = \"\"\"Alice: Good morning, team. Let's get started on our Q3 marketing campaign planning. \\n Bob: Morning, Alice. First up, we need to finalize the campaign budget. I've drafted a spreadsheet with three scenarios (low, medium, high spend) and emailed it to everyone. \\n Charlie: Got itâ€”Bob, can you share that in the #marketing Slack channel by end of day? \\nBob: Yes, I'll post it there by 5 PM today.\\n Alice: Great. Next, social media strategy. Dana, you were going to propose some new platforms for influencer outreach?\\n Dana: Right. I'm evaluating two micr\\n Emily: On it. I'll draft initial outreach emails and share a template by Thursday.\\n Alice: Finally, we need copy for the landing page. Frank, can you write the first draft?\\n Frank: I'll draft the copy by Monday morning and circulate it for feedback.\\n Alice: Awesome. Let's recap action items:\\n - **Bob**: Post budget scenarios spreadsheet to #marketing Slack by 5 PM today.\\n  - **Dana**: Deliver influencer-network recommendation deck by Wednesday.\\n  - **Emily**: Share outreach email template by Thursday.\\n    - **Frank**: Draft landing-page copy by Monday morning.\\n  \\nThanks, everyoneâ€”meeting adjourned!\\n\"\"\"\n",
    "\n",
    "# ----Run chain------------------------\n",
    "response = chain.invoke({\"title\": meeting_title, \"text\": meeting_text})\n",
    "print(f\"Actions items for {response['title']}\\n\")\n",
    "for action in response[\"actions\"]: \n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE**\n",
    "Modify the previous example to read in the generated txt file and output actions to a separate txt file.  \n",
    "\n",
    "**Read the file from path \"/content/{meeting_title}.txt\"** \\\n",
    "**Output a new file at path \"/content/{meeting_title}: Action Items.txt\"** \\\n",
    "**The output file should contain each action item on a new line.** \n",
    "\n",
    "```bash\n",
    "# To read \n",
    "p = Path(\"content/MyMeeting.txt\")\n",
    "text = p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# To write \n",
    "p = Path(\"content/MyMeeting: Action Items.txt\")\n",
    "p.write_text(actions, encoding=\"utf-8\")\n",
    "\n",
    "# To join with new line character\n",
    "\"\\n\".join(lines)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m p.write_text(meeting_text, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# ----Run chain------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeeting_title\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4719\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4705\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4706\u001b[39m \n\u001b[32m   4707\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4716\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4726\u001b[39m     msg = (\n\u001b[32m   4727\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4728\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4729\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4573\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4571\u001b[39m                 output = chunk\n\u001b[32m   4572\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4573\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4574\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dmls-langchain-workshop/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mcreate_actions\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_actions\u001b[39m(data): \n\u001b[32m     29\u001b[39m     response = llm.invoke(\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         action_template.format_prompt(text=\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m).to_messages()\n\u001b[32m     31\u001b[39m     ).content.strip()\n\u001b[32m     32\u001b[39m     action_items = [\n\u001b[32m     33\u001b[39m         line.strip(\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response.splitlines()\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m line.strip().startswith(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m     ]\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     39\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m], \n\u001b[32m     40\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mactions\u001b[39m\u001b[33m\"\u001b[39m: action_items\n\u001b[32m     41\u001b[39m     }\n",
      "\u001b[31mKeyError\u001b[39m: 'text'"
     ]
    }
   ],
   "source": [
    "# ... Previous runnables, templates, etc.\n",
    "\n",
    "\"\"\"\n",
    "You may define helper functions to achieve TODO #1 and #2\n",
    "\n",
    "TODO#1 - create runnable to read the file \n",
    "TODO#2 - create runnable to write the generated actions to a new txt file\n",
    "TODO#3 - modify chain with the new runnables\n",
    "\"\"\"\n",
    "\n",
    "# ******************CODE HERE*****************\n",
    "\n",
    "# ----Assemble chain------------------------\n",
    "chain = extract_actions | parse_actions\n",
    "\n",
    "# *******************DO NOT MODIFY BELOW*******************\n",
    "\n",
    "# ----Generate txt file------------------------\n",
    "meeting_title = \"Business Meeting 2025-05-01\"\n",
    "meeting_text = \"\"\"Alice: Good morning, team. Let's get started on our Q3 marketing campaign planning. \\n Bob: Morning, Alice. First up, we need to finalize the campaign budget. I've drafted a spreadsheet with three scenarios (low, medium, high spend) and emailed it to everyone. \\n Charlie: Got itâ€”Bob, can you share that in the #marketing Slack channel by end of day? \\nBob: Yes, I'll post it there by 5 PM today.\\n Alice: Great. Next, social media strategy. Dana, you were going to propose some new platforms for influencer outreach?\\n Dana: Right. I'm evaluating two micr\\n Emily: On it. I'll draft initial outreach emails and share a template by Thursday.\\n Alice: Finally, we need copy for the landing page. Frank, can you write the first draft?\\n Frank: I'll draft the copy by Monday morning and circulate it for feedback.\\n Alice: Awesome. Let's recap action items:\\n - **Bob**: Post budget scenarios spreadsheet to #marketing Slack by 5 PM today.\\n  - **Dana**: Deliver influencer-network recommendation deck by Wednesday.\\n  - **Emily**: Share outreach email template by Thursday.\\n    - **Frank**: Draft landing-page copy by Monday morning.\\n  \\nThanks, everyoneâ€”meeting adjourned!\\n\"\"\"\n",
    "\n",
    "p = Path(f\"content/{meeting_title}.txt\")\n",
    "p.write_text(meeting_text, encoding=\"utf-8\")\n",
    "\n",
    "# ----Run chain------------------------\n",
    "response = chain.invoke({\"title\": meeting_title})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"...................................................................\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"...................................................................\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\".......................SOLUTION BELOW..............................\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"...................................................................\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"...................................................................\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action items saved to content/Business Meeting 2025-05-01: Action Items.txt\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ----Define prompt templates------------------------\n",
    "action_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You extract action items from a meeting transcript.\"),\n",
    "    (\"human\", \"List the action items for this meeting transcript,\" \\\n",
    "        \"as bullet points, each starting with '- ':\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "# ----Helper functions------------------------\n",
    "def create_actions(data): \n",
    "    response = llm.invoke(\n",
    "        action_template.format_prompt(text=data[\"text\"]).to_messages()\n",
    "    ).content.strip()\n",
    "    \n",
    "    action_items = [\n",
    "        line.strip(\"- \").strip()\n",
    "        for line in response.splitlines()\n",
    "        if line.strip().startswith(\"-\")\n",
    "    ]\n",
    "\n",
    "    return {\"title\": data[\"title\"], \"actions\": action_items}\n",
    "\n",
    "def actions_to_txt(data):\n",
    "    title = data[\"title\"]\n",
    "    actions = data[\"actions\"]\n",
    "    \n",
    "    # Write actions \n",
    "    p = Path(f\"content/{title}: Action Items.txt\")\n",
    "    p.write_text(\"\\n\".join(actions), encoding=\"utf-8\")\n",
    "    return str(p) # return path for confirmation message\n",
    "\n",
    "# ----Create runnables------------------------\n",
    "load_transcript = RunnableLambda(\n",
    "    lambda inputs: {\n",
    "        \"title\": inputs[\"title\"],\n",
    "        \"text\":  Path(f\"content/{inputs['title']}.txt\").read_text(encoding=\"utf-8\")\n",
    "    }\n",
    ")\n",
    "extract_actions = RunnableLambda(create_actions)\n",
    "write_actions = RunnableLambda(actions_to_txt)\n",
    "respond_to_user = RunnableLambda(lambda path: f\"Action items saved to {path}\")\n",
    "\n",
    "# ----Assemble chain------------------------\n",
    "chain = load_transcript | extract_actions | write_actions | respond_to_user\n",
    "\n",
    "# ----Generate txt file------------------------\n",
    "meeting_title = \"Business Meeting 2025-05-01\"\n",
    "meeting_text = \"\"\"Alice: Good morning, team. Let's get started on our Q3 marketing campaign planning. \\n Bob: Morning, Alice. First up, we need to finalize the campaign budget. I've drafted a spreadsheet with three scenarios (low, medium, high spend) and emailed it to everyone. \\n Charlie: Got itâ€”Bob, can you share that in the #marketing Slack channel by end of day? \\nBob: Yes, I'll post it there by 5 PM today.\\n Alice: Great. Next, social media strategy. Dana, you were going to propose some new platforms for influencer outreach?\\n Dana: Right. I'm evaluating two micr\\n Emily: On it. I'll draft initial outreach emails and share a template by Thursday.\\n Alice: Finally, we need copy for the landing page. Frank, can you write the first draft?\\n Frank: I'll draft the copy by Monday morning and circulate it for feedback.\\n Alice: Awesome. Let's recap action items:\\n - **Bob**: Post budget scenarios spreadsheet to #marketing Slack by 5 PM today.\\n  - **Dana**: Deliver influencer-network recommendation deck by Wednesday.\\n  - **Emily**: Share outreach email template by Thursday.\\n    - **Frank**: Draft landing-page copy by Monday morning.\\n  \\nThanks, everyoneâ€”meeting adjourned!\\n\"\"\"\n",
    "\n",
    "p = Path(f\"content/{meeting_title}.txt\")\n",
    "p.write_text(meeting_text, encoding=\"utf-8\")\n",
    "\n",
    "# ----Run chain------------------------\n",
    "response = chain.invoke({\"title\": meeting_title})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parallel Processing**\n",
    "Runs multiple independent operations simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great news!  Your meeting minutes from \"Business Meeting 2025-05-01\" have been successfully saved to `content/Business Meeting 2025-05-01: Meeting Minutes.txt`.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ----Define prompt templates------------------------\n",
    "summarize_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a meeting summarizer.\"),\n",
    "    (\"human\", \"Produce a one-paragraph summary of this transcript:\\n\\n{text}\")\n",
    "])\n",
    "action_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You extract action items from a meeting transcript.\"),\n",
    "    (\"human\", \"List the action items for this meeting transcript,\" \\\n",
    "        \"as bullet points, each starting with '- ':\\n\\n{text}\")\n",
    "])\n",
    "confirmation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that confirms successful \\\n",
    "                completion of meeting processing tasks.\"),\n",
    "    (\"human\", \"\"\"\n",
    "        All processing steps have finished. Here are the details:\\n\\n\n",
    "\n",
    "        - Title: {title}\n",
    "        - Meeting minutes saved to {path}\n",
    "     \n",
    "       Send a friendly confirmation to the user that their file has been saved.\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# ----Helper functions------------------------\n",
    "def create_actions(data): \n",
    "    response = llm.invoke(\n",
    "        action_template.format_prompt(text=data[\"text\"]).to_messages()\n",
    "    ).content.strip()\n",
    "    action_items = [\n",
    "        line.strip(\"- \").strip()\n",
    "        for line in response.splitlines()\n",
    "        if line.strip().startswith(\"-\")\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"title\": data[\"title\"], \n",
    "        \"actions\": action_items\n",
    "    }\n",
    "\n",
    "def minutes_to_txt(outputs):\n",
    "    title = outputs[\"branches\"][\"summary\"][\"title\"]\n",
    "    summary = outputs[\"branches\"][\"summary\"][\"summary\"]\n",
    "    actions = \"\\n\".join(outputs[\"branches\"][\"actions\"][\"actions\"])\n",
    "\n",
    "    # Format string to be written to file\n",
    "    text = f\"\"\"\n",
    "        Title: {title} \\n\n",
    "\n",
    "        ----Summary----------\\n\n",
    "        {summary}\\n\\n\n",
    "\n",
    "        ----Action Items----------\\n\n",
    "        {actions}\\n\\n \n",
    "    \"\"\"\n",
    "\n",
    "    # Write minutes \n",
    "    p = Path(f\"content/{title}: Meeting Minutes.txt\")\n",
    "    p.write_text(text, encoding=\"utf-8\")\n",
    "    return {\n",
    "        \"path\": str(p),\n",
    "        \"title\": title,\n",
    "        \"summary\": summary, \n",
    "        \"actions\": actions\n",
    "    }\n",
    "\n",
    "# ----Create runnables------------------------\n",
    "\n",
    "# Runnables for synthesizing and file-writing \n",
    "load_transcript = RunnableLambda(\n",
    "    lambda inputs: {\n",
    "        \"title\": inputs[\"title\"],\n",
    "        \"text\":  Path(f\"content/{inputs['title']}.txt\").read_text(encoding=\"utf-8\")\n",
    "    }\n",
    ")\n",
    "summarize_transcript = RunnableLambda(\n",
    "    lambda inputs: {\n",
    "        \"title\":   inputs[\"title\"],\n",
    "        \"summary\": llm.invoke(\n",
    "            summarize_template.format_prompt(text=inputs[\"text\"]).to_messages()\n",
    "        ).content.strip()\n",
    "    }\n",
    ") # could also have used a helper function  \n",
    "extract_actions = RunnableLambda(create_actions)\n",
    "write_minutes = RunnableLambda(minutes_to_txt)\n",
    "\n",
    "# Runnable for LLM confirmation to user\n",
    "respond_to_user  = RunnableLambda(\n",
    "    lambda response: llm.invoke(\n",
    "        confirmation_template.format_prompt(\n",
    "            title=response[\"title\"],\n",
    "            path=response[\"path\"],\n",
    "        )\n",
    "        .to_messages()\n",
    "    ).content.strip()\n",
    ")\n",
    "\n",
    "# Bundle meeting-synthesizing runnables for parallel processing\n",
    "synthesize_meeting = RunnableParallel(\n",
    "    branches={ \n",
    "        \"summary\": load_transcript | summarize_transcript,\n",
    "        \"actions\": load_transcript | extract_actions,\n",
    "    }\n",
    ")\n",
    "\n",
    "# ----Assemble chain------------------------\n",
    "full_pipeline = synthesize_meeting | write_minutes | respond_to_user\n",
    "\n",
    "# ----Generate txt file------------------------\n",
    "meeting_title = \"Business Meeting 2025-05-01\"\n",
    "meeting_text = \"\"\"Alice: Good morning, team. Let's get started on our Q3 marketing campaign planning. \\n Bob: Morning, Alice. First up, we need to finalize the campaign budget. I've drafted a spreadsheet with three scenarios (low, medium, high spend) and emailed it to everyone. \\n Charlie: Got itâ€”Bob, can you share that in the #marketing Slack channel by end of day? \\nBob: Yes, I'll post it there by 5 PM today.\\n Alice: Great. Next, social media strategy. Dana, you were going to propose some new platforms for influencer outreach?\\n Dana: Right. I'm evaluating two micr\\n Emily: On it. I'll draft initial outreach emails and share a template by Thursday.\\n Alice: Finally, we need copy for the landing page. Frank, can you write the first draft?\\n Frank: I'll draft the copy by Monday morning and circulate it for feedback.\\n Alice: Awesome. Let's recap action items:\\n - **Bob**: Post budget scenarios spreadsheet to #marketing Slack by 5 PM today.\\n  - **Dana**: Deliver influencer-network recommendation deck by Wednesday.\\n  - **Emily**: Share outreach email template by Thursday.\\n    - **Frank**: Draft landing-page copy by Monday morning.\\n  \\nThanks, everyoneâ€”meeting adjourned!\\n\"\"\"\n",
    "\n",
    "p = Path(f\"content/{meeting_title}.txt\")\n",
    "p.write_text(meeting_text, encoding=\"utf-8\")\n",
    "\n",
    "# ----Run pipeline------------------------\n",
    "results = full_pipeline.invoke({\"title\": meeting_title})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Branching Processing**\n",
    "Handles dynamic decision-making, enabling adaptive workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great news!  Your \"Status Meeting 2025-06-01\" summary has been successfully saved to `content/status/Status Meeting 2025-06-01: Summary.txt`.\n",
      "Great news!  Your \"Status Meeting 2025-06-02\" summary has been successfully saved to `content/status/Status Meeting 2025-06-02: Summary.txt`.\n",
      "Great news!  Your \"Planning Meeting 2025-06-03\" file, including its action items, has been successfully processed and saved to `content/planning/Planning Meeting 2025-06-03: Action Items.txt`.\n",
      "Great news!  Your \"Planning Meeting 2025-06-04\" file, including its action items, has been successfully processed and saved to content/planning/Planning Meeting 2025-06-04: Action Items.txt.\n",
      "Great news!  Your Retro Meeting (2025-06-05) minutes have been successfully saved to `content/retro/Retro Meeting 2025-06-05: Meeting Minutes.txt`.\n",
      "Great news!  Your Retro Meeting 2025-06-06 minutes have been successfully saved to `content/retro/Retro Meeting 2025-06-06: Meeting Minutes.txt`.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LLM \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ----Define prompt templates------------------------\n",
    "summarize_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a meeting summarizer.\"),\n",
    "    (\"human\", \"Produce a one-paragraph summary of this transcript:\\n\\n{text}\")\n",
    "])\n",
    "action_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You extract action items from a meeting transcript.\"),\n",
    "    (\"human\", \"List the action items for this meeting transcript,\" \\\n",
    "        \"as bullet points, each starting with '- ':\\n\\n{text}\")\n",
    "])\n",
    "confirmation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that confirms successful \\\n",
    "                completion of meeting processing tasks.\"),\n",
    "    (\"human\", \"\"\"\n",
    "        All processing steps have finished. Here are the details:\\n\\n\n",
    "\n",
    "        - Title: {title}\n",
    "        - {task_completed} saved to {path}\n",
    "     \n",
    "       Send a friendly confirmation to the user that their file has been saved.\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# ----Helper functions------------------------\n",
    "def create_action_items(inputs): \n",
    "    response = llm.invoke(\n",
    "        action_template.format_prompt(text=inputs[\"text\"]).to_messages()\n",
    "    ).content.strip()\n",
    "    action_items = [\n",
    "        line.strip(\"- \").strip()\n",
    "        for line in response.splitlines()\n",
    "        if line.strip().startswith(\"-\")\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"title\": inputs[\"title\"], \n",
    "        \"actions\": action_items, \n",
    "        \"meeting_class\": inputs[\"meeting_class\"]\n",
    "    }\n",
    "\n",
    "def classify_meeting(inputs): \n",
    "    title = inputs[\"title\"]\n",
    "    if \"Status\" in title: \n",
    "        meeting_class = \"status\"\n",
    "    elif \"Planning\" in title: \n",
    "        meeting_class = \"planning\"\n",
    "    else: \n",
    "        meeting_class = \"retro\"\n",
    "    \n",
    "    return {**inputs, \"meeting_class\": meeting_class}\n",
    "\n",
    "def summary_to_txt(outputs): \n",
    "    title = outputs[\"title\"]\n",
    "    summary = outputs[\"summary\"]\n",
    "    meeting_class = outputs[\"meeting_class\"]\n",
    "\n",
    "    # Write summary \n",
    "    p = Path(f\"content/{meeting_class}/{title}: Summary.txt\")\n",
    "    p.write_text(summary, encoding=\"utf-8\")\n",
    "    return {\n",
    "        \"path\": str(p),\n",
    "        \"title\": title,\n",
    "        \"task_completed\": \"Meeting Summary\"\n",
    "    }\n",
    "\n",
    "def actions_to_txt(outputs): \n",
    "    title = outputs[\"title\"]\n",
    "    actions = \"\\n\".join(outputs[\"actions\"])\n",
    "    meeting_class = outputs[\"meeting_class\"]\n",
    "\n",
    "    # Write actions \n",
    "    p = Path(f\"content/{meeting_class}/{title}: Action Items.txt\")\n",
    "    p.write_text(actions, encoding=\"utf-8\")\n",
    "    return {\n",
    "        \"path\": str(p),\n",
    "        \"title\": title,\n",
    "        \"task_completed\": \"Meeting Action Items\"\n",
    "    }\n",
    "\n",
    "def minutes_to_txt(outputs):\n",
    "    title = outputs[\"branches\"][\"summary\"][\"title\"]\n",
    "    summary = outputs[\"branches\"][\"summary\"][\"summary\"]\n",
    "    actions = \"\\n\".join(outputs[\"branches\"][\"actions\"][\"actions\"])\n",
    "    meeting_class = outputs[\"branches\"][\"summary\"][\"meeting_class\"]\n",
    "\n",
    "    # Format string to be written to file\n",
    "    text = f\"\"\"\n",
    "        Title: {title} \\n\n",
    "\n",
    "        ----Summary----------\\n\n",
    "        {summary}\\n\\n\n",
    "\n",
    "        ----Action Items----------\\n\n",
    "        {actions}\\n\\n \n",
    "    \"\"\"\n",
    "\n",
    "    # Write minutes \n",
    "    p = Path(f\"content/{meeting_class}/{title}: Meeting Minutes.txt\")\n",
    "    p.write_text(text, encoding=\"utf-8\")\n",
    "    return {\n",
    "        \"path\": str(p),\n",
    "        \"title\": title,\n",
    "        \"task_completed\": \"Meeting Minutes\"\n",
    "\n",
    "    }\n",
    "\n",
    "# ----Create runnables------------------------\n",
    "\n",
    "# Runnables for synthesizing and file-writing \n",
    "load_transcript = RunnableLambda(\n",
    "    lambda inputs: {\n",
    "        \"title\": inputs[\"title\"],\n",
    "        \"text\":  Path(f\"content/data/{inputs['title']}.txt\").read_text(encoding=\"utf-8\"), \n",
    "    }\n",
    ")\n",
    "summarize_transcript = RunnableLambda(\n",
    "    lambda inputs: {\n",
    "        \"title\":   inputs[\"title\"],\n",
    "        \"summary\": llm.invoke(\n",
    "            summarize_template.format_prompt(text=inputs[\"text\"]).to_messages()\n",
    "        ).content.strip(),\n",
    "        \"meeting_class\": inputs[\"meeting_class\"]\n",
    "    }\n",
    ") \n",
    "extract_action_items = RunnableLambda(create_action_items)\n",
    "\n",
    "# Runnable for LLM confirmation to user\n",
    "respond_to_user  = RunnableLambda(\n",
    "    lambda response: llm.invoke(\n",
    "        confirmation_template.format_prompt(\n",
    "            title=response[\"title\"],\n",
    "            path=response[\"path\"],\n",
    "            task_completed=response[\"task_completed\"]\n",
    "        )\n",
    "        .to_messages()\n",
    "    ).content.strip()\n",
    ")\n",
    "\n",
    "# Parallel processing for retrospective meeting\n",
    "synthesize_meeting = RunnableParallel(\n",
    "    branches={ \n",
    "        \"summary\": summarize_transcript,\n",
    "        \"actions\": extract_action_items,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Classify meeting based on title\n",
    "determine_meeting_class = RunnableLambda(classify_meeting)\n",
    "\n",
    "# Writers \n",
    "status_writer = RunnableLambda(lambda d: summary_to_txt(d))\n",
    "planning_writer = RunnableLambda(lambda d: actions_to_txt(d))\n",
    "retro_writer    = RunnableLambda(lambda d: minutes_to_txt(d))\n",
    "\n",
    "# Determine how to process transcript based on meeting class\n",
    "brancher = RunnableBranch(\n",
    "    (lambda d: d[\"meeting_class\"]==\"status\", summarize_transcript | status_writer),\n",
    "    (lambda d: d[\"meeting_class\"]==\"planning\", extract_action_items | planning_writer),\n",
    "    (lambda d: d[\"meeting_class\"]==\"retro\", synthesize_meeting | retro_writer),\n",
    "    synthesize_meeting | retro_writer # default\n",
    ")\n",
    "\n",
    "# ----Assemble chain------------------------\n",
    "full_pipeline = RunnableSequence(\n",
    "    first=load_transcript, \n",
    "    middle=[determine_meeting_class, brancher], \n",
    "    last=respond_to_user\n",
    ")\n",
    "\n",
    "# ----Generate data------------------------\n",
    "meeting_transcripts = [\n",
    "    {\n",
    "        \"title\": \"Status Meeting 2025-06-01\",\n",
    "        \"transcript\": \"\"\"Alice (PM): Let's do our daily statusâ€”what did everyone complete yesterday?  \n",
    "                    Bob (Eng): I finished the caching layer and wrote unit tests.  \n",
    "                    Carol (QA): I ran the new tests, found two edge-case failures.  \n",
    "                    Dave (UX): I updated the loading spinner per feedback.  \n",
    "                    Alice: Great. Action items: Bob to fix edge cases; Carol to re-test; Dave to push spinner update.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Status Meeting 2025-06-02\",\n",
    "        \"transcript\": \"\"\"Alice (PM): Quick roundâ€”blockers?  \n",
    "                        Bob (Eng): Still debugging the API rate-limit errors.  \n",
    "                        Carol (QA): I need test data for the new webhook flows.  \n",
    "                        Dave (UX): Ready for review on the mobile layout.  \n",
    "                        Alice: Action items: Bob to pair with Carol on API fixes; Carol to generate test data; Dave to demo layout tomorrow.\"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"title\": \"Planning Meeting 2025-06-03\",\n",
    "        \"transcript\": \"\"\"Alice (PM): Let's plan sprint 12. Top priorities?  \n",
    "                        Bob (Eng): Finish offline-mode caching, start analytics dashboard.  \n",
    "                        Carol (QA): We should reserve time for performance testing.  \n",
    "                        Dave (UX): I'll prototype the dashboard wireframes.  \n",
    "                        Alice: Action items: Bob to break tasks into tickets; Carol to draft test plan; Dave to deliver wireframes by Friday.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Planning Meeting 2025-06-04\",\n",
    "        \"transcript\": \"\"\"Alice (PM): Next week we onboard two interns. We need mentorship tasks.  \n",
    "                        Bob (Eng): They could help with writing integration tests.  \n",
    "                        Carol (QA): They can also assist in cross-browser test matrix.  \n",
    "                        Dave (UX): I'll create style-guide docs for them.  \n",
    "                        Alice: Action items: Bob to draft test-writing guide; Carol to outline test matrix; Dave to publish style guide.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Retro Meeting 2025-06-05\",\n",
    "        \"transcript\": \"\"\"Alice (PM): What went well this sprint?  \n",
    "                        Bob (Eng): The caching layer shipped smoothly.  \n",
    "                        Carol (QA): Automation coverage improved by 15%.  \n",
    "                        Dave (UX): Users loved the updated spinner.  \n",
    "                        Alice: What didn't go well?  \n",
    "                        Bob: We underestimated API rate limits.  \n",
    "                        Carol: Test data lagged behind feature dev.  \n",
    "                        Alice: Action items: add API-limit tickets; build test-data pipeline.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Retro Meeting 2025-06-06\",\n",
    "        \"transcript\": \"\"\"Alice (PM): Sprint 11 retrospective. Wins?  \n",
    "                        Bob (Eng): Dashboard backend was stable.  \n",
    "                        Carol (QA): No major regressions.  \n",
    "                        Dave (UX): Positive user feedback on UI.  \n",
    "                        Alice: Lows?  \n",
    "                        Bob: Merge conflicts slowed us down.  \n",
    "                        Carol: Env setup was flaky.  \n",
    "                        Alice: Action items: improve branching strategy; stabilize test environments.\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Populate data directory \n",
    "Path(f\"content/data\").mkdir(parents=True, exist_ok=True)\n",
    "for meeting in meeting_transcripts: \n",
    "    p = Path(f\"content/data/{meeting['title']}.txt\")\n",
    "    p.write_text(meeting[\"transcript\"], encoding=\"utf-8\")\n",
    "\n",
    "# Create output directories\n",
    "for meeting_class in [\"status\", \"planning\", \"retro\"]: \n",
    "    Path(f\"content/{meeting_class}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----Run pipeline------------------------\n",
    "for meeting in meeting_transcripts: \n",
    "    results = full_pipeline.invoke({\"title\": meeting[\"title\"]})\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Improvements to think about....**\n",
    "\n",
    "- Processing all files in parallel\n",
    "- Dynamically classifying files - what are pros and cons of this approach?\n",
    "\n",
    "```bash\n",
    "classify_meeting_template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\",\"You are a meeting-type classifier.\"),\n",
    "  (\"human\",\"Classify this as status, planning, or retrospective:\\n\\n{text}\")\n",
    "])\n",
    "...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
