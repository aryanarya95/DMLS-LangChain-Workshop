{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain Templating: Syntax and Examples**\n",
    "\n",
    "## **ðŸ“ŒOverview**\n",
    "Prompt templates allow for the dynamic generation of prompts by inserting variables into a structured format. \\\n",
    "This enables the creation of flexible and reusable prompts for different tasks.\n",
    "\n",
    "LangChain supports multiple **templating syntaxes**, including (but not limited to):\n",
    "\n",
    "- **Basic String Formatting (`{variable}`)**  \n",
    "- **Multiple Placeholders in a Single Template (`{var1}, {var2}`)**  \n",
    "- **Tuple-Based Formatting (`(\"system\", \"text {var}\")`)**  \n",
    "- **Using `HumanMessage` Objects (`HumanMessage(content=\"text\")`)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping google-generativeai as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: google-ai-generativelanguage 0.6.16\n",
      "Uninstalling google-ai-generativelanguage-0.6.16:\n",
      "  Successfully uninstalled google-ai-generativelanguage-0.6.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.0 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies \n",
    "%pip install -q python-dotenv langchain-core langchain-google-genai langchain\n",
    "%pip uninstall -y google-generativeai google-ai-generativelanguage\n",
    "%pip install -q google-generativeai==0.8.4 google-ai-generativelanguage==0.6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obtain a Google Gemini API Key (GOOGLE COLLAB SETUP):**\n",
    "\n",
    "If you have a Google Gemini API Key: \n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below\n",
    "\n",
    "Otherwise:  \n",
    "- Go to the Google AI Studio API Console: [Google AI Studio](https://aistudio.google.com/prompts/new_chat)\n",
    "- Sign in with your Google account and create a new API key.\n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API key manually\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your_google_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Environment Variables (LOCAL SETUP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Basic String Formatting**  \n",
    "\n",
    "Uses LangChain's built-in `{}` placeholders to dynamically insert values into prompts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me an interesting fact about black holes', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Basic string \n",
    "template = \"Tell me an interesting fact about {object}\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt_template.invoke({\"object\": \"black holes\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple Placeholders in a Single Template**  \n",
    "\n",
    "Supports multiple dynamic placeholders within a single prompt template.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='You are a convincing essay writer.\\nHuman: Write an essay on why Gorillas are a reasonable pet to have in the household.\\nWriter:', additional_kwargs={}, response_metadata={})]\n",
      "The notion of a gorilla as a household pet is, to put it mildly, unconventional.  However, a closer examination, devoid of emotional bias and firmly grounded in pragmatic considerations, reveals that with sufficient resources, meticulous planning, and a profound understanding of primate behavior, a gorilla could, theoretically, be a reasonableâ€”though undeniably challengingâ€”pet.  Letâ€™s explore this seemingly absurd proposition.\n",
      "\n",
      "Firstly, the argument rests on the premise of responsible pet ownership amplified exponentially.  We wouldnâ€™t consider a goldfish without a tank; similarly, a gorilla necessitates a habitat of immense scale.  A custom-built enclosure, mimicking the gorillaâ€™s natural environment, would be essential.  This would involve significant land area, specialized climate control, and the constant presence of experienced primate caretakersâ€”a team, not a single individual.  The financial commitment would be astronomical, dwarfing the cost of even the most expensive canine or feline companions.  This immediately eliminates the vast majority of potential owners, leaving only those with the means and dedication to provide for such an extraordinary animal.\n",
      "\n",
      "Secondly, the safety and well-being of both the gorilla and the human family are paramount.  The gorillaâ€™s immense strength and unpredictable nature demand rigorous training and constant vigilance.  This necessitates employing experienced animal behaviorists and trainers from a young age, fostering a bond based on mutual respect and understanding, rather than dominance.  The enclosure would need to be designed with multiple layers of security, preventing escapes and accidental injuries.  Regular health checks and veterinary care would be crucial, requiring specialists in primate health.  The potential for injury, even with meticulous planning, remains a significant risk, necessitating comprehensive liability insurance and emergency protocols.\n",
      "\n",
      "Finally, the social and ethical considerations are undeniable.  The argument for a gorilla as a pet is not about satisfying a whimsical desire for exotic companionship; it's about contributing to conservation efforts and promoting gorilla welfare.  Obtaining a gorilla ethically would necessitate working with established conservation organizations and ensuring the animal is not taken from its natural habitat.  Furthermore, the enrichment of the gorilla's environment is crucial, providing stimulating activities and social interaction to prevent boredom and behavioral problems.  The family must be prepared for significant disruption to their daily lives, accommodating the gorilla's needs above their own convenience.\n",
      "\n",
      "In conclusion, while the idea of a gorilla as a household pet seems ludicrous at first glance, a well-resourced, meticulously planned, and ethically sound approach could theoretically render it a possibility. However, the immense financial, logistical, and ethical challenges are insurmountable for almost everyone. The reality is that gorillas belong in their natural habitats or in carefully managed sanctuaries where their complex needs can be met.  This essay serves not to endorse gorilla ownership, but rather to dissect the proposition, exposing the layers of complexity and responsibility involved.  The conclusion remains clear:  a gorilla is not a reasonable pet for the average household, and its welfare demands a far more appropriate setting.\n"
     ]
    }
   ],
   "source": [
    "# Multiple placeholders\n",
    "template_multiple = \"\"\"You are a convincing essay writer.\n",
    "Human: Write an essay on why {subject} {position}.\n",
    "Writer:\"\"\"\n",
    "prompt_multiple = ChatPromptTemplate.from_template(template_multiple)\n",
    "\n",
    "prompt = prompt_multiple.invoke({\"subject\": \"Gorillas\", \"position\": \"are a reasonable pet to have in the household\"})\n",
    "print(prompt)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tuple-Based Formatting**\n",
    "Uses tuples to format system and human messages dynamically in multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a world travel expert who provides insights on Tokyo.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are the top food experiences in Tokyo?', additional_kwargs={}, response_metadata={})]\n",
      "messages=[SystemMessage(content=\"You are an expert in art. Your task is to explain concepts related to this field.\\n        If the concept is directly related to art, provide a simple explanation.\\n        If the concept is unrelated, respond with: 'I'm sorry, but neural networks is outside my expertise in art.'\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain neural networks in simple terms.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Sure! Here's a breakdown of neural networks.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Tuple-based formatting\n",
    "messages = [\n",
    "    (\"system\", \"You are a world travel expert who provides insights on {destination}.\"),\n",
    "    (\"human\", \"What are the top {activity} experiences in {destination}?\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({\"destination\": \"Tokyo\", \"activity\": \"food\"})\n",
    "print(prompt)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# result = llm.invoke(prompt)\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using HumanMessage Objects**\n",
    "Allows structured human input messages within a LangChain chat prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a tour guide specializing in Halifax.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Describe three must-visit places.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# HumanMessage objects\n",
    "messages = [\n",
    "    (\"system\", \"You are a tour guide specializing in {location}.\"),\n",
    "    HumanMessage(content=\"Describe three must-visit places.\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({\"location\": \"Halifax\"})\n",
    "print(prompt)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# result = llm.invoke(prompt)\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Templating Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Accepted!\n",
      "- Field: phsyics\n",
      "- Concept: computers\n",
      "- Difficulty: basic\n",
      "\n",
      "A computer is a machine that can accept information (input), process it according to a set of instructions (program), and produce results (output).  Think of it like a super-fast, incredibly obedient calculator that can do much more than just arithmetic.\n",
      "\n",
      "Here's a simplified breakdown:\n",
      "\n",
      "* **Input:** This is the information you give the computer.  Examples include typing on a keyboard, clicking a mouse, or speaking into a microphone.\n",
      "\n",
      "* **Processing:** This is where the \"magic\" happens.  The computer's central processing unit (CPU), often called the \"brain\" of the computer, follows instructions from a program to manipulate the input data.  These instructions might involve calculations, sorting information, or displaying images.  The CPU does this by using its memory to store and retrieve information quickly.\n",
      "\n",
      "* **Output:** This is the result of the processing. Examples include text displayed on a screen, sounds from speakers, or images printed on a printer.\n",
      "\n",
      "* **Software (Programs):** These are sets of instructions that tell the computer what to do.  They can be anything from simple calculators to complex video games.\n",
      "\n",
      "* **Hardware:** This is the physical parts of the computer, like the keyboard, monitor, CPU, and memory.\n",
      "\n",
      "In essence, a computer takes in data, follows instructions to modify that data, and then presents the results.  The complexity lies in the sophistication of the instructions and the speed at which the processing occurs.\n"
     ]
    }
   ],
   "source": [
    "# Extended example of how to start using templating \n",
    "args_dictionary = {\"field\": \"\", \"concept\": \"\", \"difficulty\": \"\"}\n",
    "valid_difficulties = {\"basic\", \"intermediate\", \"advanced\"}\n",
    "\n",
    "# Define prompt template\n",
    "messages = [\n",
    "    (\"system\", \"\"\"You are an expert in {field}. Your role is to explain concepts clearly at the appropriate difficulty level.\n",
    "    - If the concept is relevant to {field}, provide a clear explanation at the requested difficulty.\n",
    "    - If the concept is unrelated, respond with: \"I'm sorry, but {concept} is outside my expertise in {field}.\" \"\"\"),\n",
    "    \n",
    "    (\"human\", \"Explain {concept} in {difficulty} terms.\"),    \n",
    "    \n",
    "    (\"ai\", \"Sure! Here's a breakdown of {concept} at the {difficulty} level.\")\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Get user inputs\n",
    "field = input(\"What field do you want to learn about? \").strip()\n",
    "while not field: \n",
    "    print(\"!Error!: Field cannot be empty.\")\n",
    "    field = input(\"What field do you want to learn about? \").strip()\n",
    "\n",
    "concept = input(\"What concept would you like to learn about: \").strip()\n",
    "while not concept:\n",
    "    print(\"!Error!: Field cannot be empty.\")\n",
    "    concept = input(\"What concept would you like to learn about: \").strip()\n",
    "\n",
    "difficulty = input(f\"What depth of understanding would you like to learn \\\n",
    "                   about {concept}? (basic, intermediate, advanced): \").strip().lower()\n",
    "while difficulty not in valid_difficulties: \n",
    "    print(\"Error: Please enter a valid difficulty level (basic, intermediate, advanced).\")\n",
    "    difficulty = input(f\"What depth of understanding would you like to learn \\\n",
    "                   about {concept}? (basic, intermediate, advanced): \").strip().lower()\n",
    "    \n",
    "print(\"Input Accepted!\")\n",
    "print(f\"- Field: {field}\")\n",
    "print(f\"- Concept: {concept}\")\n",
    "print(f\"- Difficulty: {difficulty}\\n\")\n",
    "\n",
    "# Update dictionary with user input\n",
    "args_dictionary.update({\n",
    "    \"field\": field,\n",
    "    \"concept\": concept,\n",
    "    \"difficulty\": difficulty\n",
    "})\n",
    "\n",
    "# Invoke prompt template \n",
    "prompt = prompt_template.invoke(args_dictionary)\n",
    "\n",
    "# Get LLM response\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
